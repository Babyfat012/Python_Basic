{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_decoder_reverse_seq.py\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(0); torch.manual_seed(0)\n",
    "\n",
    "# ===== 1) Vocab & dữ liệu toy =====\n",
    "# Vocab: PAD=0, SOS=1, EOS=2, token thực tế: 'a'=3,'b'=4,'c'=5,'d'=6\n",
    "PAD, SOS, EOS = 0, 1, 2\n",
    "TOKENS = ['a','b','c','d']\n",
    "stoi = {ch:i for i,ch in enumerate(['<pad>','<sos>','<eos>'] + TOKENS)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "V = len(stoi)  # 7\n",
    "\n",
    "def rand_seq(min_len=3, max_len=7):\n",
    "    L = random.randint(min_len, max_len)\n",
    "    seq = [stoi[random.choice(TOKENS)] for _ in range(L)]\n",
    "    return seq\n",
    "\n",
    "# Bài toán: out = reverse(in)\n",
    "def make_pair():\n",
    "    inp = rand_seq()\n",
    "    out = list(reversed(inp))\n",
    "    return inp, out\n",
    "\n",
    "# Helper: thêm <sos> / <eos>\n",
    "def wrap_inp(seq):  # encoder không cần <sos>, chỉ thêm <eos> cho chắc\n",
    "    return seq + [EOS]\n",
    "def wrap_out(seq):  # decoder cần <sos> ... <eos>\n",
    "    return [SOS] + seq + [EOS]\n",
    "\n",
    "# ===== 2) Model =====\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size=64, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        # x: [B, T_in]\n",
    "        x = self.emb(x)             # [B, T_in, E]\n",
    "        outputs, h_T = self.rnn(x)  # outputs: [B, T_in, H], h_T: [1, B, H]\n",
    "        return h_T\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size=64, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=PAD)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size, vocab_size)\n",
    "    def forward(self, y_prev, h):\n",
    "        # y_prev: [B, 1] id của token trước; h: [1,B,H]\n",
    "        e = self.emb(y_prev)           # [B,1,E]\n",
    "        out, h = self.rnn(e, h)        # out: [B,1,H]\n",
    "        logits = self.fc(out[:, -1])   # [B,V]\n",
    "        return logits, h\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc, self.dec = enc, dec\n",
    "    def forward(self, src, tgt, teacher_forcing=0.5):\n",
    "        \"\"\"\n",
    "        src: [B,T_in] (đã có EOS)\n",
    "        tgt: [B,T_out] (đã có SOS ... EOS)\n",
    "        \"\"\"\n",
    "        B, T_out = tgt.size()\n",
    "        h = self.enc(src)              # [1,B,H]\n",
    "        y = tgt[:, 0:1]                # bắt đầu bằng SOS\n",
    "        logits_all = []\n",
    "        for t in range(1, T_out):\n",
    "            logits, h = self.dec(y, h) # [B,V]\n",
    "            logits_all.append(logits)\n",
    "            use_tf = random.random() < teacher_forcing\n",
    "            next_y = tgt[:, t:t+1] if use_tf else logits.argmax(dim=-1, keepdim=True)\n",
    "            y = next_y\n",
    "        return torch.stack(logits_all, dim=1)  # [B,T_out-1,V]\n",
    "\n",
    "# ===== 3) Train loop =====\n",
    "enc = Encoder(V).to(DEVICE)\n",
    "dec = Decoder(V).to(DEVICE)\n",
    "model = Seq2Seq(enc, dec).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def tensorize(ids):\n",
    "    return torch.tensor(ids, dtype=torch.long, device=DEVICE).unsqueeze(0)  # [1,T]\n",
    "\n",
    "EPOCHS = 2000\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    inp_ids, out_ids = make_pair()\n",
    "    src = tensorize(wrap_inp(inp_ids))     # [1,T_in+1]\n",
    "    tgt = tensorize(wrap_out(out_ids))     # [1,T_out+2] (SOS ... EOS)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(src, tgt, teacher_forcing=0.5)  # [1, T_out+1, V]\n",
    "    # Mục tiêu là tgt[:,1:] (bắt đầu dự đoán sau SOS)\n",
    "    loss = criterion(logits.reshape(-1, V), tgt[:, 1:].reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if ep % 200 == 0 or ep == 1:\n",
    "        print(f\"[ep {ep}] loss={loss.item():.4f}\")\n",
    "\n",
    "# ===== 4) Inference =====\n",
    "@torch.no_grad()\n",
    "def infer(inp_tokens, max_len=20):\n",
    "    model.eval()\n",
    "    src = tensorize(wrap_inp(inp_tokens))\n",
    "    h = model.enc(src)\n",
    "    y = torch.tensor([[SOS]], device=DEVICE)\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        logits, h = model.dec(y, h)\n",
    "        pred = int(logits.argmax(dim=-1)[0].item())\n",
    "        if pred == EOS: break\n",
    "        out.append(pred)\n",
    "        y = torch.tensor([[pred]], device=DEVICE)\n",
    "    return out\n",
    "\n",
    "def pretty(ids):\n",
    "    return \" \".join(itos[i] for i in ids)\n",
    "\n",
    "# Thử nghiệm vài mẫu\n",
    "for _ in range(5):\n",
    "    inp, tgt = make_pair()\n",
    "    pred = infer(inp)\n",
    "    print(\"\\nIN :\", pretty(inp))\n",
    "    print(\"GOLD:\", pretty(list(reversed(inp))))\n",
    "    print(\"OUT:\", pretty(pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
