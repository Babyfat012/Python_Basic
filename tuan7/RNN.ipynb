{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d86136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_minimal_next_token.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ===== 1) Dữ liệu toy: He -> feels -> happy -> today -> (quay vòng) =====\n",
    "vocab = [\"He\", \"feels\", \"happy\", \"today\"]\n",
    "stoi = {w:i for i,w in enumerate(vocab)}\n",
    "itos = {i:w for w,i in stoi.items()}\n",
    "\n",
    "# Xây các cửa sổ độ dài 3 để dự đoán từ thứ 4\n",
    "# [He, feels, happy] -> today\n",
    "# [feels, happy, today] -> He\n",
    "# [happy, today, He] -> feels\n",
    "# [today, He, feels] -> happy\n",
    "windows = [\n",
    "    [\"He\", \"feels\", \"happy\"],\n",
    "    [\"feels\", \"happy\", \"today\"],\n",
    "    [\"happy\", \"today\", \"He\"],\n",
    "    [\"today\", \"He\", \"feels\"]\n",
    "]\n",
    "targets = [\"today\", \"He\", \"feels\", \"happy\"]\n",
    "\n",
    "X = torch.tensor([[stoi[w] for w in win] for win in windows])  # [batch=4, seq_len=3]\n",
    "Y = torch.tensor([stoi[t] for t in targets])                   # [batch=4]\n",
    "\n",
    "# ===== 2) Mô hình: Embedding -> RNN -> Linear =====\n",
    "class NextTokenRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int = 16, hidden_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        # Dùng RNN có sẵn của PyTorch\n",
    "        self.rnn = nn.RNN(input_size=emb_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x_ids):  # x_ids: [batch, seq_len]\n",
    "        x = self.emb(x_ids)            # [batch, seq_len, emb]\n",
    "        out, hT = self.rnn(x)          # out: [batch, seq_len, H]\n",
    "        last = out[:, -1, :]           # lấy output ở bước cuối: [batch, H]\n",
    "        logits = self.fc(last)         # [batch, V]\n",
    "        return logits\n",
    "\n",
    "model = NextTokenRNN(vocab_size=len(vocab))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "# ===== 3) Train ngắn gọn =====\n",
    "for ep in range(1, 401):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    logits = model(X)\n",
    "    loss = criterion(logits, Y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    if ep % 50 == 0 or ep == 1:\n",
    "        pred = logits.argmax(dim=-1).tolist()\n",
    "        pred_words = [itos[i] for i in pred]\n",
    "        print(f\"[ep {ep:3d}] loss={loss.item():.4f} | pred={pred_words}\")\n",
    "\n",
    "# ===== 4) Suy luận (inference): dự đoán tiếp theo cho 1 chuỗi cho trước =====\n",
    "def predict_next(words3):\n",
    "    model.eval()\n",
    "    ids = torch.tensor([[stoi[w] for w in words3]])  # [1,3]\n",
    "    with torch.no_grad():\n",
    "        logits = model(ids)\n",
    "        next_id = int(logits.argmax(dim=-1)[0])\n",
    "    return itos[next_id]\n",
    "\n",
    "print(\"\\n--- Inference ---\")\n",
    "test_seq = [\"He\", \"feels\", \"happy\"]\n",
    "print(test_seq, \"->\", predict_next(test_seq))\n",
    "test_seq = [\"feels\", \"happy\", \"today\"]\n",
    "print(test_seq, \"->\", predict_next(test_seq))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
