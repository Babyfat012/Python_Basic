{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5021f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vit_finetune_fakedata.py\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.models import ViT_B_16_Weights\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===== Dữ liệu: FakeData 224x224 (3 lớp) =====\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "train_ds = datasets.FakeData(size=600, image_size=(3,224,224),\n",
    "                             num_classes=NUM_CLASSES, transform=preprocess)\n",
    "val_ds   = datasets.FakeData(size=120, image_size=(3,224,224),\n",
    "                             num_classes=NUM_CLASSES, transform=preprocess)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# ===== Model: ViT-B/16 pretrained + thay head cuối =====\n",
    "model = models.vit_b_16(weights=weights)\n",
    "in_feats = model.heads.head.in_features          # classifier của ViT trong torchvision\n",
    "model.heads.head = nn.Linear(in_feats, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# (Tuỳ chọn) Freeze backbone khi data nhỏ:\n",
    "# for name, p in model.named_parameters():\n",
    "#     if not name.startswith(\"heads\"):\n",
    "#         p.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.05)\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train(train)\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y in dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        if train: optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "EPOCHS = 3\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, True)\n",
    "    va_loss, va_acc = run_epoch(val_dl, False)\n",
    "    print(f\"[Epoch {ep}] train_loss={tr_loss:.4f} acc={tr_acc:.3f} | val_loss={va_loss:.4f} acc={va_acc:.3f}\")\n",
    "\n",
    "# ===== Inference nhanh một batch validation =====\n",
    "model.eval()\n",
    "x, y = next(iter(val_dl))\n",
    "x = x.to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    pred = model(x).argmax(1).cpu()\n",
    "print(\"GT[:8]:\", y[:8].tolist())\n",
    "print(\"PR[:8]:\", pred[:8].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
